{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"community/acknowledgements/","text":"<p></p> <p>Carbyne Stack development is partially funded by the Federal Ministry of Education and Research under Grant Agreement No. 16KIS1441 for the publicly-funded CRYPTECS project. The content made available on this website reflects the view of the Carbyne Stack community only. The Research Executive Agency is not responsible for any use that may be made of the information it contains.</p>","title":"Acknowledgements"},{"location":"community/ecosystem/","text":"<p> </p> <p>Robert Bosch GmbH started the Carbyne Stack open source project in September 2021 by contributing an internally developed code base, and now maintains the project and contributes regularly. Carbyne Stack is used by Bosch to conduct proof-of-concepts in multiple domains with various partners.</p>  <p> </p> <p>The Honda Research Institute Europe (HRI-EU) researches future technologies advancing cooperative intelligent systems that will shape our future in many ways, ranging from autonomous and accident-free driving to personal robots and from smart design and manufacturing to the privacy-preserving use of data. The privacy of users and customers is one of HRI's essential goals, and they aim to live up to the trust of their customers. HRI-EU contributes together with academic and innovative partners to Carbyne Stack to implement this vision.</p>  <p> </p> <p>University of Technology Sydney, Bosch, and Food Agility CRC have joined forces to work on the publicly funded project Collaborative privacy-preserving Digital Agriculture. One research track is focussing on Federated Learning with MPC-based hardware-accelerated secure aggregation. The research results will eventually be implemented by a UTS engineering team based on Carbyne Stack.</p>","title":"Carbyne Stack Ecosystem"},{"location":"community/events/","text":"","title":"Events featuring Carbyne Stack"},{"location":"community/events/#upcoming-events","text":"","title":"Upcoming Events"},{"location":"community/events/#tpmpc-22","text":"<p>Open Source Cloud-Native MPC (Invited Talk)</p> <p></p> <p>JUNE 7 - 10, 2022 | AARHUS (DENMARK).</p>  <p>Abstract</p> <p>Not available yet.</p>","title":"TPMPC '22"},{"location":"community/events/#oss-na-22","text":"<p>Carbyne Stack - Cloud Native Computing on Encrypted Data (Contributed Talk)</p> <p></p> <p>JUNE 21 - 24, 2022 | AUSTIN, TEXAS (US).</p>  <p>Abstract</p> <p>Data has become a strategic asset that is pooled with others for joint  processing, monetized on data platforms, and used to fuel the AI revolution. As the ability to leverage internal and external data is becoming a major factor for business success, protecting valuable data is more important than ever. Enter Computing On Encrypted Data technologies (COEDs). COEDs pave the way for strong end-to-end protection of data by enabling encryption in use. One roadblock for the wider adoption of COEDs so far has been the lack of integration with state-of-the-art cloud technology to enable scalable, resilient, and easy to operate COED deployments. The Carbyne Stack open-source project has set out to close this gap by lifting a specific COED technology called Secure Multiparty Computation (MPC) into the cloud. Sven will take the audience down the rabbit hole of COED technologies and explain how Carbyne Stack blends cloud-native technology (including Kubernetes, Istio, Knative, and others) to solve the specific challenges of deploying MPC in the cloud like cross-cluster orchestration of MPC services and serverless provisioning of MPC workloads. </p>","title":"OSS-NA '22"},{"location":"community/events/#stackconf-22","text":"<p>Scaling the Grail - Cloud-Native Computing on Encrypted Data using Carbyne Stack (Contributed Talk)</p> <p></p> <p>JULY 19 \u2013 20, 2022 | BERLIN (GERMANY)</p>  <p>Abstract</p> <p>Computing on Encrypted Data (CoED) is considered a holy grail of data security. A major roadblock for the adoption of CoEDs is a lack of integration with cloud technologies to enable scalable, resilient, and easy to operate deployments. The Carbyne Stack open-source project has set out to close this gap. This talk will take the audience down the rabbit hole of CoED technologies and explain how Carbyne Stack blends cloud-native technologies to solve the challenges of scaling sensitive workloads.</p>","title":"StackConf '22"},{"location":"community/events/#past-events","text":"","title":"Past Events"},{"location":"community/events/#bocse-22","text":"<p>Computing on Encrypted Data \u2013 A hands-on tutorial using the Open Source Carbyne Stack Secure Multiparty Computation Platform (Tutorial)</p> <p></p> <p>APRIL 4 \u2013 7, 2022 | VIRTUAL (Bosch internal)</p>  <p>Abstract</p> <p>Computing on Encrypted Data (CoED) technology is a new mind-boggling way of protecting data in use. CoEDs can be used to implement IT systems where sensitive data is encrypted end-to-end: in transit, at rest, and even in use. CoEDs will play an increasingly important role in the future when it comes to protecting sensitive information in collaborative environments or meeting the requirements of increasingly stringent, diverse, and pervasive data protection regulations in our target markets.</p> <p>Participants of this tutorial will get to know the fundamentals of a CoED technology called Secure Multiparty Computation (MPC) that allows a set of mutually distrusting parties to securely compute a function of their private inputs, revealing only the output, even if some of the parties are corrupt. Participants will learn how to author simple MPC programs using a state-of-the-art MPC engine and how to use the Carbyne Stack open source cloud MPC platform to deploy MPC workloads in a scalable way. In addition, attendees will learn about the roadmap for the Carbyne Stack platform and how they can contribute to its development.</p>","title":"BoCSE '22"},{"location":"community/gsoc/","text":"<p>Rejected for GSoC 2022</p> <p>Sadly, we have not been accepted for GSoC 2022. We plan to apply again in 2023 and hope that we have better luck then. Stay tuned!</p> <p>Still the topics mentioned below are very relevant for the Carbyne Stack community. In case you are interested in working on one of them or you have your own ideas on how to advance the Carbyne Stack project or community, please do not hesitate to get in touch. We'll probably find a way to get you supported by one of the backing organizations. Please also have a look at the opportunities page for open positions. </p>  <p>Carbyne Stack is applying to become a Google Summer of Code (GSoC) 2022 mentoring organization. For those not aware of what GSoC is, here comes the official description from Google:</p>  <p>What is Google Summer of Code?</p> <p>Google Summer of Code is a global, online program focused on bringing new contributors into open source software development.  (Source: GSoC Website)</p>  <p>Students interested in becoming a contributor to the Carbyne Stack open source project as part of the GSoC programme can find all the information related to our participation as a mentoring organization on this page.</p>","title":"Google Summer of Code"},{"location":"community/gsoc/#application-101","text":"<p>Want to apply for working with Carbyne Stack in GSoC 2022? Great! Read below what it needs to get things going1.</p>","title":"Application 101"},{"location":"community/gsoc/#how-to-apply","text":"<p>Application only via GSoC System</p> <p>All applications must go through Google's GSoC application system. We can't accept any application unless it is submitted there.</p>  <p>Applying is not witchcraft as long as you take the following points to heart:</p> <ol> <li>Read carefully all the information provided on this page and in the GSoC    student guide.</li> <li>Get in touch with the Carbyne Stack maintainers    ( Caryne Stack Maintainers)    or with your prospective mentors (see contact information below in the    topics list) in case you want to discuss your project idea or understand    better the expectations towards GSoC applicants.</li> <li>Write your application. See hints on this below.</li> <li>Submit your application to Google before the deadline. We actually recommend    you to submit a few days early in case you have internet problems or the    system is down. Google does not extend this deadline, so it's best to be    prepared early! You can edit your application up until the system closes.</li> </ol>","title":"How to Apply"},{"location":"community/gsoc/#anatomy-of-a-good-application","text":"<p>A promising application will contain at least:</p> <ol> <li>A descriptive title for the project. In case you are interested in one    of the projects proposed by us that should be straightforward. Otherwise,    put some effort into to this as it's the first opportunity to trigger the    interest of potential mentors.</li> <li>A concise CV with a special focus on your practical experiences with    relevant technology and open source projects, including contact information.    No problem if you don't have that much experience yet, as long as you have    the skills to master the envisioned project.</li> <li>Information about your (proposed) project. This should be reasonably    detailed and include a timeline with concrete milestones. Please also    include any learning tasks that you anticipate to get you prepared for    mastering your GSoC project.</li> <li>Information about other commitments that might affect your ability to    work during the GSoC period (exams, classes, holidays, other jobs, weddings,    etc.). We can work around a lot of things, but it helps to know in advance.</li> </ol>","title":"Anatomy of a good Application"},{"location":"community/gsoc/#topics","text":"<p>We have an attractive mix of potential GSoC project proposals. Each project is rated according to effort (, either <code>175h</code> or <code>350h</code>) and difficulty / complexity (, one of <code>Easy</code>, <code>Medium</code>, or <code>Hard</code>). While projects rated low complexity tend to require adapting a single or a small number of Carbyne Stack software components (like a microservice) only, those with high complexity require contributors to get a good understanding of the Carbyne Stack system as a whole or require in-depth knowledge of a single or a few components.</p>  <p>BYOT (Bring Your Own Topic)</p> <p>In case you have your own small or big idea how to advance Carbyne Stack or our open source community, don't hesitate to get in touch ( GSoC Organization Administrator) to discuss your proposal.</p>   <p>Tip</p> <p>Please use the tabs below to navigate through the GSoC project proposals.</p>  Core DevelopmentInfrastructure &amp; Automation   <p>Core development projects derive from the ongoing work from the core of our development team. The list of features and bugs is never-ending, and help is always welcome. Expect to be closely integrated into the frequent interactions of the Carbyne Stack core development team.</p> Carbyne Stack OperatorCloud-native Authentication and AuthorizationMigrate to gRPC   <p>Carbyne Stack Operator</p> <p> 175h (Basic), 350h (Extended)  Hard</p> <p>Operators are software extensions to Kubernetes that make use of custom resources to manage applications and their components. Carbyne Stack is  a complex system consisting of multiple independently scalable  microservices with interwoven configuration requirements. This project is about implementing a Kubernetes operator that can be used to deploy, configure, and operate a Carbyne Stack virtual cloud provider and to establish virtual clouds by interconnecting multiple of them.</p> <p>Expected Outcomes</p>  <p>Value Proposition</p> <p>DevOps will be able to easily deploy and operate Carbyne Stack virtual clouds.</p>  <p>Technical Key Results</p> Basic (175h)Extended (350h)   <ul> <li>A set of basic operators for Carybne Stack microservices, i.e.,   Castor, Amphora, Ephemeral is available.</li> </ul>   <ul> <li>A set of basic operators for Carybne Stack microservices, i.e.,   Castor, Amphora, Ephemeral is available.</li> <li>An additional \"super\" operator is implemented that can be used to   deploy a complete Carbyne Stack virtual cloud provider and that   provides mechanisms to establish a Carbyne Stack virtual cloud    by partnering with remote virtual cloud providers. This process   includes things like key generation, CA certificate exchange, and   parameter negotiation.</li> </ul>    <p>Required Skills</p> <ul> <li>Advanced coding skills in Go or Java</li> <li>(Bonus) Experience with an operator framework, e.g., Operator    SDK, kubebuilder, or the Java Operator SDK</li> <li>(Bonus) Knowledge on Carbyne Stack including how microservices work   and how their configurations \"interact\"</li> </ul> <p>Potential Mentors</p> <ul> <li>Sven Trieflinger (Robert Bosch GmbH)</li> </ul>   <p>Cloud-native Authentication and Authorization</p> <p> 350h  Medium</p> <p>In this project, the CNCF projects Dex and OPA will be used to implement OIDC authentication and policy-based authorization in the Carbyne Stack microservices, clients and CLI in a cloud-native way.</p> <p>Expected Outcomes</p>  <p>Value Proposition</p> <p>End-users will be able to define who is able to access Amphora secrets, Castor tuples, and Ephemeral functions.</p>  <p>Technical Key Results</p> <ul> <li>Authorization support is implemented in Carbyne Stack microservices   including Amphora, Castor, and Ephemeral. </li> <li>End-user authentication support is set up using Istio features.</li> <li>Support for Authentication and Authorization is implemented in Java   clients and CLI.</li> </ul> <p>Required Skills</p> <ul> <li>Good coding skills in Java and Go</li> <li>Experience in working with K8s</li> <li>Basic knowledge about authentication standards, in particular OIDC</li> <li>(Bonus) Experience with Dex and OPA</li> </ul> <p>Potential Mentors</p> <ul> <li>Sebastian Becker (Robert Bosch GmbH)</li> <li>Sven Trieflinger (Robert Bosch GmbH)</li> <li>Jared Weinfurtner (Robert Bosch GmbH)</li> </ul>   <p>Migrate to gRPC</p> <p> 175h (Basic), 350h (Extended)  Easy</p> <p>As of today, communication in Carbyne Stack is based on a mix of REST and WebSockets. In this project, you get your feets wet with gRPC, the CNCF high performance, open source universal RPC framework  and use  gRPC to replace the communication protocols used currently in Carbyne Stack.</p> <p>Expected Outcomes</p>  <p>Value Proposition</p> <p>Developers will be able to use a modern and fast RPC framework to interact with the Carbyne Stack services.</p>  <p>Technical Key Results</p> Basic (175h)Extended (350h)   <ul> <li>Castor service and clients are migrated to gRPC.</li> </ul>   <ul> <li>Castor service and clients are migrated to gRPC.</li> <li>Amphora service and clients are migrated to gRPC.</li> </ul>    <p>Required Skills</p> <ul> <li>Good coding skills in Java</li> <li>Solid understanding of the RPC and REST paradigms</li> <li>(Bonus) Previous experience in working with gRPC</li> </ul> <p>Potential Mentors</p> <ul> <li>Sebastian Becker (Robert Bosch GmbH)        </li> <li>Sven Trieflinger (Robert Bosch GmbH)</li> <li>Jared Weinfurtner (Robert Bosch GmbH)</li> </ul>      <p>Infrastructure and automation projects are about things somewhat orthogonal to core development. Expect to work a little bit more indepedently but not really detached from the core developer team. Nevertheless, you will contribute things equally important that will be highly appreciated by the community.</p> Security HardeningPublic Cloud Deployment   <p>Security Hardening</p> <p> 175h (Basic), 350h (Extended)  Medium</p> <p>This project is about securing Carbyne Stack deployments in various aspects including east-west (intra-VCP) and north-south (inter-VCP) traffic using the open source Istio service mesh, Kubernetes RBAC configuration, and secrets management using Hashicorp Vault.</p> <p>Expected Outcomes</p>  <p>Value Proposition</p> <p>DevOps will be able to securely operate CS virtual cloud providers.</p>  <p>Technical Key Results</p> Basic (175h)Extended (350h)   <ul> <li>East-west (intra-VCP) inter-service communication channels are   secured using Istio service-to-service Mutual TLS authentication.</li> <li>North-south (inter-VCP) communication channels are secured using   an Istio mutual TLS ingress gateway.</li> <li>Namespace isolation and RBAC policies for Carbyne Stack K8s   resources are in place.</li> </ul>   <ul> <li>East-west (intra-VCP) inter-service communication channels are   secured using Istio service-to-service Mutual TLS authentication.</li> <li>North-south (inter-VCP) communication channels are secured using   an Istio mutual TLS ingress gateway.</li> <li>Namespace isolation and RBAC policies for Carbyne Stack K8s   resources are in place.</li> <li>Secret management is implemented using Hashicorp Vault for MPC   MAC and encryption keys, as well as local and remote    certificates.</li> </ul>    <p>Required Skills</p> <ul> <li>Experience in working with K8s</li> <li>Solid understanding of TLS and Istio</li> <li>(Bonus) Previous experience with Hashicorp Vault</li> </ul> <p>Potential Mentors</p> <ul> <li>Sven Trieflinger (Robert Bosch GmbH)</li> </ul>   <p>Public Cloud Deployment</p> <p> 175h  Easy</p> <p>Carbyne Stack currently comes along with instructions for local deployment of a virtual cloud on kind clusters using MetalLB as the bare-metal load balancer. The goal of this project is to provide modern deployment machinery for a public cloud using the Terraform infrastructure as code software tool.</p> <p>Expected Outcomes</p>  <p>Value Proposition</p> <p>DevOps will be able to deploy Carbyne Stack virtual cloud providers to a public cloud.</p>  <p>Technical Key Results</p> <ul> <li>IaC code for deploying a Carbyne Stack virtual cloud (provider) to   Azure based on Terraform and helm is available.</li> </ul> <p>Required Skills</p> <ul> <li>Basic skills in working with an IaC tool</li> <li>Familarity with Helm</li> <li>Experience in working with a public cloud</li> <li>(Bonus) Experience with Azure Public Cloud and Terraform</li> </ul> <p>Potential Mentors</p> <ul> <li>Sven Trieflinger (Robert Bosch GmbH)</li> </ul>","title":"Topics"},{"location":"community/gsoc/#faq","text":"<p>Why do we want to participate in GSoC?</p> <p>We are passionate about the ideas behind Carbyne Stack and the possibilities cloud-native Secure Multiparty Computation opens up for secure and privacy-friendly processing of sensitive data. With Carbyne Stack being a security-related enabling technology project, we think going down the open source path is exactly the right way to go.</p> <p>By participating in the GSoC program, we aim to attract the interest of tech-savvy, highly skilled people who are passionate about open source and help them expand their skills while making useful contributions to the Carbyne Stack platform to make it even better.</p>  <p>What would we consider to be a successful GSoC?</p> <p>Our foremost goal is to spark long-term interest in Carbyne Stack. A successful GSoC would give us active community members who have come to stay.</p> <p>As a young open source project and first-time participant in the GSoC program, there is plenty for us to learn. In the best case, this year's participation will lay the foundation for regular participation in the program.</p> <p>We believe that the GSoC projects we propose will add significant value to the Carbyne Stack developer and user community. We will do our best to ensure that GSoC contributions actually find their way into the Carbyne Stack codebase.</p>  <p>How will we keep mentors engaged with their GSoC contributors?</p> <p>We only accept mentors who we know well, who are active members of the community, and who are fully aware of their responsibilities as GSoC mentors.</p> <p>We foster the exchange of knowledge and best practices between mentors in regular mentoring meetings.</p> <p>As administrators of the mentoring organization, we see it as one of our main tasks to keep the mentors engaged and spend enough time to make sure that everything runs smoothly.</p>  <p>How will we keep GSoC contributors involved in our community during (and after) GSoC?</p> <p>We host community meetings every two weeks. GSoC contributors are invited to attend these meetings to present their work, interact with community members, and receive the input and guidance they need to achieve their project goals. Weekly meetings with their mentors help participants learn about relevant activities within the community. All (written) interaction within the community takes place on GitHub, which keeps the barriers to entry low for GSoC students.</p> <p>The participating industry partners regularly offer opportunities to interested students to do internships or academic theses on topics related to Carbyne Stack within their company. This might be interesting for certain GSoC contributors as a way to keep in touch with the community after GSoC will have come to an end.</p>  <p>How will we help our GSoC contributors stay on schedule to complete their projects?</p> <p>We will implement the following measures to ensure the success of GSoC projects for both GSoC students and us:</p> <ul> <li>Mentors will meet weekly with their mentees to identify and address emerging   issues early.</li> <li>GSoC contributors are invited to attend our regular community meetings, and   are encouraged to interact with others in the community via regular GitHub   communication channels or email.</li> <li>Code reviews are an integral part of our routine within the Carbyne Stack   community - not only as a quality measure, but also as a means of knowledge   transfer. This routine is naturally extended to GSoC contributions as well.</li> </ul> <p>Have we been accepted as a GSoC mentor organization before?</p> <p>Carbyne Stack is a young open source project kick-started some months back in September 2021 by means of an initial contribution by Bosch Research. Therefore, it is our first time applying as GSoC mentoring organization.</p> <p>Where does our source code live?\"</p> <p>Our project and community is hosted on GitHub under the Carbyne Stack organization.</p>   <ol> <li> <p>Based on the excellent guideline examples given on the GSoC website, in particular the Python GSoC website.\u00a0\u21a9</p> </li> </ol>","title":"FAQ"},{"location":"community/media-coverage/","text":"<p>This page summarizes media coverage of Carbyne Stack in blog posts, articles and news.</p>  <ul> <li> <p><p> Blog Post</p></p>  <p></p> <p>Lifting Computing on Encrypted Data into the Cloud - Bosch Research launches Carbyne Stack Open-Source Project for Cloud-Native Secure Multiparty Computation</p> <p> Bosch Research Blog</p> </li> </ul>","title":"Media Coverage"},{"location":"community/opportunities/","text":"<p>Find below a compilation of current job offerings and other opportunities to work in the wider ecosystem around Carbyne Stack:</p>","title":"Opportunities to Contribute"},{"location":"community/opportunities/#robert-bosch-gmbh","text":"<ol> <li>Working student Open source software development for cloud-native privacy preserving computing (f/m/div.) \u279d Job Ad</li> <li>Internship Open Source Community Data Mining and Analytics (f/m/div.) \u279d Job Ad</li> </ol>","title":"Robert Bosch GmbH"},{"location":"community/opportunities/#university-of-technology-sydney","text":"<ol> <li>PhD position with scholarship in publicly funded project on Collaborative Privacy-Preserving Digital Agriculture working on MPC-based hardware-accelerated Federated Learning based on Carbyne Stack. \u279d Job Ad</li> </ol>","title":"University of Technology Sydney"},{"location":"community/participate/","text":"","title":"Participate in the Carbyne Stack Community"},{"location":"community/participate/#community-meetings","text":"<p>We host public Carbyne Stack Community Meetings on  Discord, open to anyone interested in the Carbyne Stack open source project, every first and third Monday of the month at 3pm CE(S)T.</p> <p>Everyone interested is welcome to attend!</p>","title":"Community Meetings"},{"location":"getting-started/","text":"","title":"Getting Started with Carbyne Stack"},{"location":"getting-started/#tldr","text":"<p>Watch the following video to learn about the core concepts and services of the Carbyne Stack MPC Cloud Platform and how they can be used to solve the Millionaires' Problem or to recognize handwritten letters via privacy-friendly Machine Learning.</p>       Sorry, your browser doesn't support embedded videos.","title":"TL;DR"},{"location":"getting-started/#hands-on-tutorials","text":"<p>Our hands-on tutorials will walk you through the basics of the Carbyne Stack Native MPC platform and how to set up and run simple experiments with it.</p> <p>You will</p> <ol> <li>Understand the basic architecture and abstractions of the Carbyne    Stack platform.</li> <li>Set up Kubernetes clusters with all the prerequisites    required for deploying a Carbyne Stack Virtual Cloud Provider including Istio    and Knative.</li> <li>Deploy a fully functional Carbyne Stack Virtual Cloud to these    clusters.</li> <li>Learn how to solve the canonical Millionaires Problem    leveraging the Carbyne Stack CLI.</li> </ol>  <p>Tip</p> <p>Have fun and let us know in case you encounter any obstacles or problems.</p>","title":"Hands-On Tutorials"},{"location":"getting-started/deployment/","text":"<p>This guide describes how to set up a Carbyne Stack Virtual Cloud (VC) consisting of two Virtual Cloud Providers (VCP).</p>","title":"Stack Deployment Guide"},{"location":"getting-started/deployment/#prerequisites","text":"<p>Warning</p> <p>Carbyne Stack has been tested using the exact versions of the tools specified below. Deviating from this battle tested configuration may create all kinds of issues.</p>  <ul> <li>Helmfile v0.142.0</li> <li>Helm v3.7.1</li> <li>Helm Diff Plugin v3.1.3</li> </ul> <p>In addition, this guide assumes you have access to two properly configured K8s clusters (herein referred to as <code>apollo</code> and <code>starbuck</code>) with the following components:</p> <ul> <li>Kubernetes v1.18.19</li> <li>Istio v1.7.3</li> <li>MetalLB v0.9.3</li> <li>Knative v0.19.0</li> <li>Zalando Postgres Operator v1.5.0</li> </ul> <p>Throughout the remainder of this guide, we assume that you have set up local clusters using the kind tool as described in the Platform Setup guide.</p>","title":"Prerequisites"},{"location":"getting-started/deployment/#virtual-cloud-deployment","text":"<p>Tip</p> <p>In case you are on a slow internet connection, you can use</p> <pre><code>kind load docker-image &lt;image&gt; --name &lt;cluster-name&gt;\n</code></pre> <p>to load images from your local docker registry into the kind clusters. This  way you have to download the images only once and then reuse them across VCP deployments.</p>  <ol> <li> <p>Checkout out the carbynestack repository    and descend into the repository root directory using:</p> HTTPSSH   <pre><code>git clone https://github.com/carbynestack/carbynestack.git\ncd carbynestack\n</code></pre>   <pre><code>git clone git@github.com:carbynestack/carbynestack.git\ncd carbynestack\n</code></pre>    </li> <li> <p>Before deploying the virtual cloud providers make some common configuration    available using:</p>  <p>Attention</p> <p>Replace <code>172.18.1.128</code> and <code>172.18.2.128</code> with the load balancer IPs assigned to the Istio Ingress Gateway by MetalLB (see the Platform Setup guide).</p>  <pre><code>export APOLLO_FQDN=\"172.18.1.128.sslip.io\"\nexport STARBUCK_FQDN=\"172.18.2.128.sslip.io\"\nexport RELEASE_NAME=cs\nexport DISCOVERY_MASTER_HOST=$APOLLO_FQDN\nexport NO_SSL_VALIDATION=true\n</code></pre> </li> <li> <p>Launch the <code>starbuck</code> VCP using:</p> <pre><code>export FRONTEND_URL=$STARBUCK_FQDN\nexport IS_MASTER=false\nexport AMPHORA_VC_PARTNER_URI=http://$APOLLO_FQDN/amphora\nkubectl config use-context kind-starbuck\nhelmfile apply\n</code></pre> </li> <li> <p>Launch the <code>apollo</code> VCP using:</p> <pre><code>export FRONTEND_URL=$APOLLO_FQDN\nexport IS_MASTER=true\nexport AMPHORA_VC_PARTNER_URI=http://$STARBUCK_FQDN/amphora\nexport CASTOR_SLAVE_URI=http://$STARBUCK_FQDN/castor\nkubectl config use-context kind-apollo\nhelmfile apply\n</code></pre> </li> <li> <p>Wait until all pods in both clusters are in the <code>ready</code> state.</p> </li> </ol>","title":"Virtual Cloud Deployment"},{"location":"getting-started/deployment/#preparing-the-virtual-cloud","text":"<ol> <li> <p>Carbyne Stack comes with a CLI that can be used to interact with a virtual    cloud from the command line. Install the CLI using:</p> <pre><code>export CLI_VERSION=0.1-SNAPSHOT-1576571202-7-cf3db5b\ncurl -o cs.jar -L https://github.com/carbynestack/cli/releases/download/$CLI_VERSION/cli-$CLI_VERSION-jar-with-dependencies.jar\n</code></pre> </li> <li> <p>Next configure the CLI to talk to the just deployed virtual cloud by creating    a matching CLI configuration file in <code>~/.cs</code> using:</p> <pre><code>mkdir -p ~/.cs\ncat &lt;&lt;EOF | envsubst &gt; ~/.cs/config\n{\n  \"prime\" : 198766463529478683931867765928436695041,\n  \"r\" : 141515903391459779531506841503331516415,\n  \"noSslValidation\" : true,\n  \"trustedCertificates\" : [ ],\n  \"providers\" : [ {\n    \"amphoraServiceUrl\" : \"http://$APOLLO_FQDN/amphora\",\n    \"castorServiceUrl\" : \"http://$APOLLO_FQDN/castor\",\n    \"ephemeralServiceUrl\" : \"http://$APOLLO_FQDN/\",\n    \"id\" : 1,\n    \"baseUrl\" : \"http://$APOLLO_FQDN/\"\n  }, {\n    \"amphoraServiceUrl\" : \"http://$STARBUCK_FQDN/amphora\",\n    \"castorServiceUrl\" : \"http://$STARBUCK_FQDN/castor\",\n    \"ephemeralServiceUrl\" : \"http://$STARBUCK_FQDN/\",\n    \"id\" : 2,\n    \"baseUrl\" : \"http://$STARBUCK_FQDN/\"\n  } ],\n  \"rinv\" : 133854242216446749056083838363708373830\n}\nEOF\n</code></pre> <p>Alternatively, you can use the CLI tool itself to do the configuration by providing the respective values (as seen above in the HEREDOC) when asked using:</p> <pre><code>java -jar cs.jar configure\n</code></pre> <p>You can verify that the configuration works by fetching telemetry data from castor using:</p>  <p>Attention</p> <p>Replace <code>&lt;#&gt;</code> with either <code>1</code> for the <code>apollo</code> cluster or <code>2</code> for the <code>starbuck</code> cluster.</p>  <pre><code>java -jar cs.jar castor get-telemetry &lt;#&gt;\n</code></pre> </li> </ol>","title":"Preparing the Virtual Cloud"},{"location":"getting-started/deployment/#upload-offline-material","text":"<p>Before you can actually use the services provided by the Virtual Cloud, you have to upload cryptographic material. As generating offline material is a very time-consuming process, we provide pre-generated material.</p>  <p>Danger</p> <p>Using pre-generated offline material is not secure at all. DO NOT DO THIS IN A PRODUCTION SETTING.</p>  <ol> <li> <p>Download and decompress the archive containing the material using:</p> <pre><code>curl -O -L https://github.com/carbynestack/base-images/raw/3595c5427915b2f9e1f22804e3f742cda9e72312/fake-crypto-material.zip\nunzip -d crypto-material fake-crypto-material.zip\nrm fake-crypto-material.zip\n</code></pre> </li> <li> <p>Upload and activate tuples using:</p>  <p>Tip</p> <p>Adapt the <code>NUMBER_OF_CHUNKS</code> variable in the following snippet to tune the number of uploaded tuples. In case<code>NUMBER_OF_CHUNKS &gt; 1</code> the same tuples are uploaded repeatedly.</p>  <pre><code>cat &lt;&lt; 'EOF' &gt; upload-tuples.sh\n#!/bin/bash\nSCRIPT_PATH=\"$( cd \"$(dirname \"$0\")\" ; pwd -P )\"\nTUPLE_FOLDER=${SCRIPT_PATH}/crypto-material/2-128-40\nCLI_PATH=${SCRIPT_PATH}\nNUMBER_OF_CHUNKS=1\n\nfunction uploadTuples {\n   echo ${NUMBER_OF_CHUNKS}\n   for type in INPUT_MASK_GFP MULTIPLICATION_TRIPLE_GFP; do\n      for (( i=0; i&lt;${NUMBER_OF_CHUNKS}; i++ )); do\n         local chunkId=$(uuidgen)\n         echo \"Uploading ${type} to http://${APOLLO_FQDN}/castor (Apollo)\"\n         java -jar ${CLI_PATH}/cs.jar castor upload-tuple -f ${TUPLE_FOLDER}/Triples-p-P0 -t ${type} -i ${chunkId} 1\n         local statusMaster=$?\n         echo \"Uploading ${type} to http://${STARBUCK_FQDN}/castor (Starbuck)\"\n         java -jar ${CLI_PATH}/cs.jar castor upload-tuple -f ${TUPLE_FOLDER}/Triples-p-P1 -t ${type} -i ${chunkId} 2\n         local statusSlave=$?\n         if [[ \"${statusMaster}\" -eq 0 &amp;&amp; \"${statusSlave}\" -eq 0 ]]; then\n            java -jar ${CLI_PATH}/cs.jar castor activate-chunk -i ${chunkId} 1\n            java -jar ${CLI_PATH}/cs.jar castor activate-chunk -i ${chunkId} 2\n         else\n            echo \"ERROR: Failed to upload one tuple chunk - not activated\"\n         fi\n      done\n   done\n}\n\nuploadTuples\nEOF\nchmod 755 upload-tuples.sh\n./upload-tuples.sh\n</code></pre> </li> <li> <p>You can verify that the uploaded tuples are now available for use by the    Carbyne Stack services using:</p>  <p>Attention</p> <p>Replace <code>&lt;#&gt;</code> with either <code>1</code> for the <code>apollo</code> cluster or <code>2</code> for the <code>starbuck</code> cluster.</p>  <pre><code>java -jar cs.jar castor get-telemetry &lt;#&gt;\n</code></pre> </li> </ol> <p>You now have a fully functional Carbyne Stack Virtual Cloud at your hands.</p>","title":"Upload Offline Material"},{"location":"getting-started/deployment/#teardown-the-virtual-cloud","text":"<p>You can tear down the Virtual Cloud by tearing down the Virtual Cloud Providers using:</p> <pre><code>for var in apollo starbuck\ndo\n  kubectl config use-context kind-$var\n  helmfile destroy\ndone\n</code></pre>","title":"Teardown the Virtual Cloud"},{"location":"getting-started/millionaires/","text":"<p>In this tutorial, you will learn how to solve the millionaires problem using an MPC function deployed on Carbyne Stack.</p>","title":"Solving the Millionaires Problem"},{"location":"getting-started/millionaires/#prerequisites","text":"<p>You need a deployed Carbyne Stack Virtual Cloud and the Carbyne Stack CLI. Please see the Platform Setup Guide and the Deployment Guide for instructions on how to get hold of these.</p> <p>In addition, this guide assumes that you have the following tools installed:</p> <ul> <li>Java 8 (newer versions will not work)</li> </ul>","title":"Prerequisites"},{"location":"getting-started/millionaires/#the-billionaires-problem","text":"<p>We use a variation of Andrew Yao's Millionaires' Problem that is the secure multi-party computation problem of deciding which of two millionaires, Alice and Bob, is richer without revealing their actual wealth. Since the conception of the problem, the world has moved on and we better speak today not of two millionaires but of two (completely fictional) billionaires called Jeff and Elon.</p> <p>In the following, we describe how to solve this problem using Carbyne Stack. To see how things work, let's put ourselves in Elon's shoes.</p>","title":"The Billionaires Problem"},{"location":"getting-started/millionaires/#providing-the-inputs","text":"<p>First, we upload the inputs into the Carbyne Stack Amphora Secret Store. The inputs are the billionaires' net worth in billions. Note that this obviously has to be done in a private way by Jeff and Elon in a real-world setting.</p> <pre><code># Create a secret representing Jeff's net worth (note that we work with \n# billion USD here)\nexport JEFFS_NET_WORTH_ID=$(java -jar cs.jar amphora create-secret 177 -t billionaire=Jeff)\n\n# And another one for Elon\nexport ELONS_NET_WORTH_ID=$(java -jar cs.jar amphora create-secret 151 -t billionaire=Elon)\n</code></pre> <p>We can check the secrets have been created using:</p> <pre><code>java -jar cs.jar amphora get-secrets\n</code></pre> <p>The output should resemble the following:</p>  <p>Note</p> <p>The output you see will differ wrt. identifiers and the <code>creation-date</code> tag.</p>  <pre><code>ab160f93-3b7e-468f-b687-f9c46fb535f3\n    billionaire -&gt; Jeff\n    creation-date -&gt; 1630660117946\nef3e867f-9233-46fb-9cde-7a09c99bc32f\n    billionaire -&gt; Elon\n    creation-date -&gt; 1630660125951\n</code></pre>","title":"Providing the Inputs"},{"location":"getting-started/millionaires/#invoke-the-billionaires-function","text":"<p>Elon is eager to see whether he ranks first in the list of the richest people in the world. To check that using the Carbyne Stack platform, a well-known global media company which regularly publishes a list of the richest people in the world came up with the following MP-SPDZ program that does the job:</p> <pre><code>cat &lt;&lt; 'EOF' &gt; billionaires.mpc\n# Prologue to read in the inputs\nport=regint(10000)\nlisten(port)\nsocket_id = regint()\nacceptclientconnection(socket_id, port)\nv = sint.read_from_socket(socket_id, 2)\n\n# The logic\nfirst_billionaires_net_worth = v[0]\nsecond_billionaires_net_worth= v[1]\nresult = first_billionaires_net_worth &lt; second_billionaires_net_worth\n\n# Epilogue to return the outputs \nresp = Array(1, sint)\nresp[0] = result\nsint.write_to_socket(socket_id, resp)\nEOF\n</code></pre> <p>The program expects two inputs and does a simple comparison between them. The result written as a secret to Amphora at the end of the program is either <code>1</code> in case the first input is less than the second or <code>0</code> otherwise.</p> <p>Elon invokes the program using the Ephemeral Serverless Compute Service as follows:</p> <pre><code>export RESULT_ID=$(cat billionaires.mpc | java -jar cs.jar ephemeral execute \\\n  -i $JEFFS_NET_WORTH_ID \\\n  -i $ELONS_NET_WORTH_ID \\\n  ephemeral-generic.default \\\n  | tail -n +2 \\\n  | sed 's/[][]//g')\n</code></pre> <p>The CLI spits out a list of identifiers of Amphora Secrets generated by the program. The snippet above extracts the single identifier emitted in this example and stores it in the <code>RESULT_ID</code> shell variable.</p> <p>Using this identifier Elon can inspect the result of the execution using:</p> <pre><code>java -jar cs.jar amphora get-secret $RESULT_ID\n</code></pre> <p>The output being <code>0</code> tells Elon that unfortunately Jeff is still the alpha:</p> <pre><code>[0]\n    creation-date -&gt; 1630661192626\n    gameID -&gt; 7899b23c-4509-4ff8-a9ae-d9b59fa77fea\n</code></pre> <p>After buying a bunch of the fabulous new (and completely fictional) Carbyne Stack Altcoins and posting a tweet that one of his companies will accept that coin for payments in the future, Elon wants to see whether he is finally in the pole position. He deletes his old and submits his new net worth and triggers the evaluation of the Billionaires Problem logic again using:</p> <pre><code>java -jar cs.jar amphora delete-secrets $ELONS_NET_WORTH_ID\nexport ELONS_NET_WORTH_ID=$(java -jar cs.jar amphora create-secret 179 -t billionaire=Elon)\nexport RESULT_ID=$(cat billionaires.mpc | java -jar cs.jar ephemeral execute \\\n  -i $JEFFS_NET_WORTH_ID \\\n  -i $ELONS_NET_WORTH_ID \\\n  ephemeral-generic.default \\\n  | tail -n +2 \\\n  | sed 's/[][]//g')\njava -jar cs.jar amphora get-secret $RESULT_ID\n</code></pre> <p>This time the execution results in a '1', which creates a pleasantly warm feeling in Elon's chest.</p>","title":"Invoke the Billionaires Function"},{"location":"getting-started/millionaires/#next-steps","text":"<p>This simple tutorial showcased only a small subset of the Carbyne Stack's capabilities. Feel free to explore the possibilities yourself by playing around with the CLI.</p>","title":"Next Steps"},{"location":"getting-started/overview/","text":"<p>This guide describes the basic architecture and fundamental abstractions of the Carbyne Stack platform.</p>","title":"Overview"},{"location":"getting-started/overview/#clientserver-style-mpc","text":"<p>Secure Multiparty Computation (MPC) is a cryptographic technique that distributes a computation among multiple parties in such a way that no single party can see the other parties' data.</p> <p>Carbyne Stack implements SPDZ-like (see [1]) MPC in the client/server model, first described by Damg\u00e5rd et al. in [2]. In this variant of MPC, computations are offloaded by clients to a set of servers that act as the MPC parties.</p> <p>Translated to the Carbyne Stack universe, this means, we can have a set of Carbyne Stack deployments acting as the MPC parties1 and any number of clients invoking the services provided collectively by the Carbyne Stack deployments. In Carbyne Stack lingo, we refer to the MPC parties as Virtual Cloud Providers (VCPs) that jointly provide MPC services in a Virtual Cloud (VC).</p>","title":"Client/Server-style MPC"},{"location":"getting-started/overview/#carbyne-stack-services","text":"<p>Each VCP hosts a set of elementary services called Castor, Amphora, and Ephemeral that together implement a fully functional cloud-native MPC party ( see Figure 1):</p> <ul> <li> <p>Castor stores data-independent tuples generated in the MPC   offline phase2 and serves them on request to Amphora and Ephemeral.</p> </li> <li> <p>Amphora is the secret store that is used by clients to store   and retrieve secrets. Secrets are stored as secret shares on the distributed   Amphora instances in a VC. They can be used as inputs to an Ephemeral   computation or are created as results of such a computation. Amphora uses   data-independent tuples from Castor to facilitate secure up-/download in the   client/server setting as described in [1].</p> </li> <li> <p>Ephemeral is used to execute programs using   the MP-SPDZ MPC framework. Any number of secrets can be fetched   from Amphora at the beginning of an MPC program execution and any number of   secrets can be written to Amphora at the end. Ephemeral fetches tuples from   Castor consumed throughout the execution of the MPC program.</p> </li> </ul>    Figure 1: Carbyne Stack comprising the data store and     compute services, clients, and a CLI","title":"Carbyne Stack Services"},{"location":"getting-started/overview/#communication-interfaces","text":"<p>The VCP services interact locally, with their counterparts in other VCPs, and with clients (see Figure 2). There are three communication interfaces involved:</p> <ul> <li> <p>The Intra-VCP Interface is used to communicate internally within a VCP.   For example, Ephemeral talks to the co-located Castor service to fetch offline   tuples using the intra-vcp interface3.</p> </li> <li> <p>The Inter-VCP Interface is used to coordinate operations among VCPs. An   example for this is the interaction required between Amphora instances to   perform the secure up-/download protocols mentioned above.</p> </li> <li> <p>The Client Interface is used by clients to invoke the Carbyne Stack   services provided by a VC, e.g., uploading a secret to Amphora or triggering   an MPC program execution via Ephemeral.</p> </li> </ul>    Figure 2: The Carbyne stack components and the interfaces through     which they communicate","title":"Communication Interfaces"},{"location":"getting-started/overview/#scalability","text":"<p>A central design goal of Carbyne Stack is that each of the VCP services can be scaled independently and automatically. To achieve this, the Carbyne Stack microservices are implemented as Kubernetes services (Castor and Amphora) and as Knative applications (Ephemeral). This allows the scaling mechanisms of these platforms to be used to react dynamically to fluctuating load patterns.</p>","title":"Scalability"},{"location":"getting-started/overview/#bibliography","text":"<p>[1] Ivan Damg\u00e5rd, Valerio Pastro, Nigel Smart, Sarah Zakarias: Multiparty computation from somewhat homomorphic encryption. In: Safavi-Naini, R., Canetti, R. (eds.) Advances in Cryptology \u2013 CRYPTO 2012. Lecture Notes in Computer Science, vol. 7417, pp. 643\u2013662. Springer, Heidelberg, Germany, Santa Barbara, CA, USA (Aug 19\u201323, 2012)</p> <p>[2] Ivan Damg\u00e5rd, Kasper Damg\u00e5rd, Kurt Nielsen, Peter Sebastian Nordholt, Tomas Toft: Confidential Benchmarking based on Multiparty Computation. In Grossklags, J. and Preneel, B. (eds.) Financial Cryptography and Data Security, pp.169\u2013187. Springer.</p>   <ol> <li> <p>Only two-party settings are supported by Carbyne Stack as of now.\u00a0\u21a9</p> </li> <li> <p>Tuples must be generated externally and uploaded using the CLI as of today. A future release of Carbyne Stack will include a service called Klyshko to generate tuples in a scalable manner.\u00a0\u21a9</p> </li> <li> <p>Note that currently tuples baked into the container image are used by Ephemeral. Fetching the tuples from Castor will be implemented in a future release.\u00a0\u21a9</p> </li> </ol>","title":"Bibliography"},{"location":"getting-started/platform-setup/","text":"<p>This guide describes how to prepare K8s clusters using <code>kind</code> that are suitable for deploying a two-party Carbyne Stack Virtual Cloud. After completing the steps described below, you should have two kind K8s clusters called <code>apollo</code> and <code>starbuck</code> with the following pods deployed:</p> <pre><code>kubectl get pods -A\nNAMESPACE            NAME                                           READY   STATUS    RESTARTS   AGE\ndefault              knative-operator-7fc877bffd-f9qdh              1/1     Running   0          115s\ndefault              postgres-operator-74f9948c5f-l8mpd             1/1     Running   0          24s\nistio-operator       istio-operator-6d7958b7bf-j5f78                1/1     Running   0          4m10s\nistio-system         istio-ingressgateway-7b757f7699-4sjk9          1/1     Running   0          3m10s\nistio-system         istiod-7556f7fddf-4gg6t                        1/1     Running   0          3m26s\nknative-serving      activator-749f4f58bd-bvgvk                     1/1     Running   0          66s\nknative-serving      autoscaler-848955c655-7ndxc                    1/1     Running   0          65s\nknative-serving      controller-8c7b5f59c-d7brb                     1/1     Running   0          65s\nknative-serving      istio-webhook-566b5df9f-6fhvt                  1/1     Running   0          61s\nknative-serving      net-certmanager-webhook-5886f5f5cb-26sbr       1/1     Running   0          59s\nknative-serving      networking-certmanager-6b5cb4b9d6-c4gl2        1/1     Running   0          60s\nknative-serving      networking-istio-795f8cd665-27vcs              1/1     Running   0          61s\nknative-serving      webhook-5fd89bbf5-gghtq                        1/1     Running   0          64s\nkube-system          coredns-66bff467f8-ht8hb                       1/1     Running   0          4m20s\nkube-system          coredns-66bff467f8-vsndf                       1/1     Running   0          4m20s\nkube-system          etcd-apollo-control-plane                      1/1     Running   0          4m30s\nkube-system          kindnet-jht6w                                  1/1     Running   0          4m20s\nkube-system          kube-apiserver-apollo-control-plane            1/1     Running   0          4m30s\nkube-system          kube-controller-manager-apollo-control-plane   1/1     Running   0          4m30s\nkube-system          kube-proxy-w5dfw                               1/1     Running   0          4m20s\nkube-system          kube-scheduler-apollo-control-plane            1/1     Running   0          4m30s\nlocal-path-storage   local-path-provisioner-59c6df4d-962pq          1/1     Running   0          4m20s\nmetallb-system       controller-57f648cb96-vgtsp                    1/1     Running   0          3m15s\nmetallb-system       speaker-c8lq5                                  1/1     Running   0          3m15s\n</code></pre>","title":"Platform Setup Guide"},{"location":"getting-started/platform-setup/#prerequisites","text":"<p>Warning</p> <p>Carbyne Stack has been tested using the exact versions of the tools specified below. Deviating from this battle tested configuration may create all kinds of issues.</p> <p>Do not forget to perform the post installation steps  for Docker.</p>   <p>Info</p> <p>You'll need at least 3 GB of memory and 1 CPU core per kind cluster to deploy Carbyne Stack. Depending on the actual workloads you are going to deploy, these numbers can be considerably higher.</p>  <ul> <li>Docker Engine v20.10.6</li> <li>Kind v0.11.0</li> <li>kubectl v1.21.1</li> <li>Helm v3.7.1</li> </ul>","title":"Prerequisites"},{"location":"getting-started/platform-setup/#setting-up-the-clusters","text":"","title":"Setting up the Clusters"},{"location":"getting-started/platform-setup/#kind-clusters","text":"<p>You will need two Carbyne Stack Virtual Cloud Providers deployed to separate K8s clusters to complete this getting started guide. The clusters are called <code>apollo</code> and <code>starbuck</code>. You can use the <code>--name &lt;name&gt;</code> option to launch a kind cluster with K8s context name <code>kind-&lt;name&gt;</code>, as follows:</p> ApolloStarbuck   <pre><code>kind create cluster --name apollo --image kindest/node:v1.18.19\n</code></pre>   <pre><code>kind create cluster --name starbuck --image kindest/node:v1.18.19\n</code></pre>    <p>You can switch between the clusters easily using:</p> ApolloStarbuck   <pre><code>kubectl config use-context kind-apollo\n</code></pre>   <pre><code>kubectl config use-context kind-starbuck\n</code></pre>     <p>Important</p> <p>Complete the remaining steps of this guide for the <code>apollo</code> cluster and then repeat for <code>starbuck</code>.</p>","title":"Kind Clusters"},{"location":"getting-started/platform-setup/#istio","text":"<ol> <li> <p>Install    the Istio Operator    v1.7.3 using:</p> <pre><code>curl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.7.3 TARGET_ARCH=x86_64 sh -\nhelm install istio-operator istio-1.7.3/manifests/charts/istio-operator \\\n  --set operatorNamespace=istio-operator \\\n  --set watchedNamespaces=\"istio-system\" \\\n  --set hub=\"docker.io/istio\" \\\n  --set tag=\"1.7.3\"\n</code></pre> </li> <li> <p>Create an Istio Control Plane in a dedicated namespace using:</p> <pre><code>cat &lt;&lt;EOF &gt; istio-control-plane.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: istio-system\n---\napiVersion: install.istio.io/v1alpha1\nkind: IstioOperator\nmetadata:\n  namespace: istio-system\n  name: cs-istiocontrolplane\nspec:\n  meshConfig:\n    accessLogFile: /dev/stdout\n  components:\n    ingressGateways:\n      - name: istio-ingressgateway\n        enabled: true\n        k8s:\n          resources:\n            requests:\n              cpu: 10m\n              memory: 40Mi\n          service:\n            ports:\n              ## You can add custom gateway ports in user values overrides, \n              # but it must include those ports since helm replaces.\n              # Note that AWS ELB will by default perform health checks on \n              # the first port on this list. Setting this to the health \n              # check port will ensure that health checks always work. \n              # https://github.com/istio/istio/issues/12503\n              - port: 15021\n                targetPort: 15021\n                name: status-port\n              - port: 80\n                targetPort: 8080\n                name: http2\n              - port: 443\n                targetPort: 8443\n                name: https\n              - port: 31400\n                targetPort: 31400\n                name: tcp\n                # This is the port where sni routing happens\n              - port: 15443\n                targetPort: 15443\n                name: tls\n              - port: 30000\n                name: ephemeral-mpc-engine-port-0\n              - port: 30001\n                name: ephemeral-mpc-engine-port-1\n              - port: 30002\n                name: ephemeral-mpc-engine-port-2\n              - port: 30003\n                name: ephemeral-mpc-engine-port-3\n              - port: 30004\n                name: ephemeral-mpc-engine-port-4\n    pilot:\n      k8s:\n        env:\n          - name: PILOT_TRACE_SAMPLING\n            value: \"100\"\n        resources:\n          requests:\n            cpu: 10m\n            memory: 100Mi\n  values:\n    global:\n      proxy:\n        resources:\n          requests:\n            cpu: 10m\n            memory: 40Mi\n    pilot:\n      autoscaleEnabled: false\n    gateways:\n      istio-egressgateway:\n        autoscaleEnabled: false\n      istio-ingressgateway:\n        autoscaleEnabled: false\nEOF\nkubectl apply -f istio-control-plane.yaml\n</code></pre> </li> </ol>","title":"Istio"},{"location":"getting-started/platform-setup/#metallb","text":"<ol> <li> <p>Install MetalLB v0.9.3 using:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/namespace.yaml\nkubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/metallb.yaml\nkubectl create secret generic -n metallb-system memberlist --from-literal=secretkey=\"$(openssl rand -base64 128)\"\n</code></pre> </li> <li> <p>Configure MetalLB using:</p> ApolloStarbuck   <pre><code>export SUBNET=172.18.1.255/25\ncat &lt;&lt;EOF | envsubst &gt; metallb.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: default\n      protocol: layer2\n      addresses:\n      - ${SUBNET}\n      avoid-buggy-ips: true\nEOF\nkubectl apply -f metallb.yaml\n</code></pre>   <pre><code>export SUBNET=172.18.2.255/25\ncat &lt;&lt;EOF | envsubst &gt; metallb.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: default\n      protocol: layer2\n      addresses:\n      - ${SUBNET}\n      avoid-buggy-ips: true\nEOF\nkubectl apply -f metallb.yaml\n</code></pre>    </li> <li> <p>Wait until an external IP has been assigned to the Istio Ingress Gateway by    MetalLB:</p> <pre><code>kubectl get services --namespace istio-system istio-ingressgateway -w\n</code></pre> </li> </ol> <p>The public IP eventually appears in column <code>EXTERNAL-IP</code>.</p> <ol> <li> <p>Export the external IP for later use:</p> <pre><code>export EXTERNAL_IP=$(kubectl get services --namespace istio-system istio-ingressgateway --output jsonpath='{.status.loadBalancer.ingress[0].ip}')\n</code></pre> </li> </ol>","title":"MetalLB"},{"location":"getting-started/platform-setup/#knative","text":"<ol> <li> <p>Install the    Knative Operator    v0.19.0 using:</p> <pre><code>kubectl apply -f https://github.com/knative/operator/releases/download/v0.19.0/operator.yaml\n</code></pre> </li> <li> <p>Create a namespace for Knative Serving using:</p> <pre><code>kubectl create namespace knative-serving\n</code></pre> </li> <li> <p>Install the patched Knative Serving component with a    sslip.io custom domain using:</p> <pre><code>cat &lt;&lt;EOF | envsubst &gt; knative-serving.yaml\napiVersion: operator.knative.dev/v1alpha1\nkind: KnativeServing\nmetadata:\n  name: knative-serving\n  namespace: knative-serving\nspec:\n  version: 0.19.0\n  manifests:\n    - URL: https://github.com/carbynestack/serving/releases/download/v0.19.0_multiport-patch/serving-crds.yaml\n    - URL: https://github.com/carbynestack/serving/releases/download/v0.19.0_multiport-patch/serving-core.yaml\n    - URL: https://github.com/knative/net-istio/releases/download/v0.19.0/release.yaml\n    - URL: https://github.com/knative/net-certmanager/releases/download/v0.19.0/release.yaml\n  config:\n     domain:\n        ${EXTERNAL_IP}.sslip.io: \"\"\nEOF\nkubectl apply -f knative-serving.yaml\n</code></pre> </li> </ol>","title":"Knative"},{"location":"getting-started/platform-setup/#postgres-operator","text":"<p>Deploy the Zalando Postgres operator v1.5.0 using:</p> <pre><code>curl -sL https://github.com/zalando/postgres-operator/archive/refs/tags/v1.5.0.tar.gz | tar -xz\nhelm install postgres-operator postgres-operator-1.5.0/charts/postgres-operator\n</code></pre>","title":"Postgres Operator"},{"location":"getting-started/platform-setup/#clean-up","text":"<p>If you no longer need the cluster you can tear it down using:</p> ApolloStarbuck   <pre><code>kind delete cluster --name apollo\n</code></pre>   <pre><code>kind delete cluster --name starbuck\n</code></pre>","title":"Clean Up"},{"location":"getting-started/platform-setup/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"getting-started/platform-setup/#openvpn","text":"<p>In case you use OpenVPN and encounter an error message when launching a kind cluster like</p> <pre><code>ERROR: failed to create cluster: failed to ensure docker network: command \"docker network create -d=bridge -o com.docker.network.bridge.enable_ip_masquerade=true -o com.docker.network.driver.mtu=1500 --ipv6 --subnet fc00:f853:ccd:e793::/64 kind\" failed with error: exit status 1\nCommand Output: Error response from daemon: could not find an available, non-overlapping IPv4 address pool among the default\n</code></pre> <p>follow the advice given here.</p>","title":"OpenVPN"},{"location":"getting-started/prerequisites/","text":"<p>This guide describes how to install the prerequisites required to deploy Carbyne Stack.</p>  <p>Warning</p> <p>Carbyne Stack has been tested using the exact versions of the tools specified below. Deviating from this battle tested configuration may create all kinds of issues.</p>","title":"Setting up the prerequisites"},{"location":"getting-started/prerequisites/#prerequisites","text":"<p>This part of the tutorial is developed and tested with Ubuntu 20.04. Please refer to this link for Ubuntu installation steps.</p>","title":"Prerequisites"},{"location":"getting-started/prerequisites/#platform-setup-prerequisites","text":"<p>Software to be installed:</p> <ul> <li>go 1.18</li> <li>Docker Engine v20.10.6</li> <li>Kind v0.11.0</li> <li>kubectl v1.21.1</li> <li>Helm v3.7.1</li> </ul> <p>Please set the following software version strings before you continue with our installation instructions.</p> <pre><code>export go_ver=1.18\nexport dock_ver=5:20.10.6~3-0~ubuntu-focal\nexport kind_ver=0.11.0\nexport kub_ver=1.21.1\nexport helm_ver=3.7.1\n</code></pre>","title":"Platform Setup Prerequisites"},{"location":"getting-started/prerequisites/#go","text":"<p>The go language is a prerequisite for the Kind package. In this guideline go 1.18 will be installed. Detailed installation instructions for go can be found here. Alternatively, you can install go by following the instructions below.</p> <ol> <li> <p>Download go language for Linux.</p> <pre><code>wget https://go.dev/dl/go$go_ver.linux-amd64.tar.gz\n</code></pre> </li> <li> <p>Extract to <code>/usr/local</code>. You may need to insert the password for sudo permissions.</p> <pre><code>sudo tar -C /usr/local -xzf go$go_ver.linux-amd64.tar.gz\n</code></pre> </li> <li> <p>Check if there is a <code>go</code> folder in <code>/usr/local</code>.</p> <pre><code>ls /usr/local\n</code></pre> </li> <li> <p>Update <code>PATH</code> for go with the commands below.</p> <pre><code>echo 'export PATH=$PATH:/usr/local/go/bin' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> </li> <li> <p>Verify if <code>PATH</code> is updated. Now go 1.18 is successfully installed.</p> <pre><code>go version\n</code></pre> </li> </ol>","title":"go"},{"location":"getting-started/prerequisites/#docker-engine","text":"<p>Detailed installation instructions for Docker Engine can be found here. Alternatively, you can install Docker Engine by following the instructions below.</p> <ol> <li> <p>Update repository index and install dependencies.</p> <pre><code>sudo apt-get update\nsudo apt-get install ca-certificates curl gnupg lsb-release\n</code></pre> </li> <li> <p>Add Docker\u2019s official GPG key.</p> <pre><code>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n</code></pre> </li> <li> <p>Set up the stable repository.</p> <pre><code>echo \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre> </li> <li> <p>Install Docker Engine with the commands below.</p> <pre><code>sudo apt-get update\nsudo apt-get install docker-ce=$dock_ver docker-ce-cli=$dock_ver containerd.io\n</code></pre> </li> <li> <p>Manage Docker as a non-root user.</p> <pre><code>sudo groupadd docker\nsudo usermod -aG docker $USER\nnewgrp docker\n</code></pre> </li> <li> <p>Verify the installation.</p> <pre><code>docker run hello-world\n</code></pre> </li> </ol>","title":"Docker Engine"},{"location":"getting-started/prerequisites/#kind","text":"<p>Detailed installation instructions for Kind can be found here. Alternatively, you can install Kind by following the instructions below.</p> <ol> <li> <p>Install Kind 0.11.0.</p> <pre><code>go install sigs.k8s.io/kind@v$kind_ver\n</code></pre> </li> <li> <p>Add the local go path to <code>PATH</code>. You may have a different go path. Please check <code>GOPATH</code> with <code>go env</code> and replace <code>~/go</code> in the below command with your <code>GOPATH</code>.</p> <pre><code>echo 'export PATH=$PATH:~/go/bin' &gt;&gt; ~/.bashrc \nsource ~/.bashrc\n</code></pre> </li> <li> <p>Verify Kind installation.</p> <pre><code>kind version\n</code></pre> </li> </ol>","title":"Kind"},{"location":"getting-started/prerequisites/#kubectl","text":"<p>Detailed installation instructions for kubectl can be found here. Alternatively, you can install kubectl by following the instructions below.</p> <ol> <li> <p>Download kubectl 1.21.1.</p> <pre><code>curl -LO https://dl.k8s.io/release/v$kub_ver/bin/linux/amd64/kubectl\n</code></pre> </li> <li> <p>Install kubectl with the command below.</p> <pre><code>sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n</code></pre> </li> <li> <p>Verify the installation.</p> <pre><code>kubectl version --client\n</code></pre> </li> </ol>","title":"kubectl"},{"location":"getting-started/prerequisites/#helm","text":"<p>Detailed installation instructions for the Helm package manager can be found here. Alternatively, you can install Helm by following the instructions below.</p> <ol> <li> <p>Download the Helm package manager.</p> <pre><code>wget https://get.helm.sh/helm-v$helm_ver-linux-amd64.tar.gz\n</code></pre> </li> <li> <p>Unpack the downloaded compressed file.</p> <pre><code>tar -zxvf helm-v$helm_ver-linux-amd64.tar.gz\n</code></pre> </li> <li> <p>Move the unpacked content (the <code>helm</code> file) to <code>PATH</code>.</p> <pre><code>sudo mv linux-amd64/helm /usr/local/bin/helm\n</code></pre> </li> <li> <p>Verify your installation.</p> <pre><code>helm version\n</code></pre> </li> </ol>","title":"Helm"},{"location":"getting-started/prerequisites/#stack-deployment-prerequisites","text":"<p>Software to be installed:</p> <ul> <li>Helmfile v0.142.0</li> <li>Helm Diff Plugin v3.1.3</li> <li>OpenJDK 8</li> </ul> <p>Please set the following software version strings before you continue with our installation instructions.</p> <pre><code>export helmfile_ver=0.142.0\nexport helmdiff_ver=3.1.3\n</code></pre>","title":"Stack Deployment Prerequisites"},{"location":"getting-started/prerequisites/#helmfile","text":"<p>Detailed installation instructions for the Helmfile package can be found here. Alternatively, you can install Helmfile by following the instructions below.</p> <ol> <li> <p>Download the Helmfile package.</p> <pre><code>wget https://github.com/roboll/helmfile/releases/download/v$helmfile_ver/helmfile_linux_amd64\n</code></pre> </li> <li> <p>Give execution permission to Helmfile.</p> <pre><code>chmod +x helmfile_linux_amd64\n</code></pre> </li> <li> <p>Move Helmfile to <code>PATH</code>.</p> <pre><code>sudo mv helmfile_linux_amd64 /usr/local/bin/helmfile\n</code></pre> </li> <li> <p>Verify your installation.</p> <pre><code>helmfile -v\n</code></pre> </li> </ol>","title":"Helmfile"},{"location":"getting-started/prerequisites/#helm-diff-plugin","text":"<p>Detailed installation instructions for the Helm Diff plugin can be found here. Alternatively, you can install Helm Diff by following the instructions below.</p> <ol> <li> <p>Download Helm Diff plugin compressed file.</p> <pre><code>wget https://github.com/databus23/helm-diff/releases/download/v$helmdiff_ver/helm-diff-linux.tgz\n</code></pre> </li> <li> <p>Unpack the compressed file.</p> <pre><code>tar -zxvf helm-diff-linux.tgz\n</code></pre> </li> <li> <p>Put the unpacked contents into the helm plugins folder. You may have a different folder. Please check <code>HELM_PLUGINS</code> with <code>helm env</code> command. Please create the folders if they do not exist. Note that the <code>diff</code> folder must not exist in the helm plugins folder before executing the command below.</p> <pre><code>mv diff ~/.local/share/helm/plugins/diff\n</code></pre> </li> <li> <p>Verify your installation.</p> <pre><code>helm plugin list\n</code></pre> </li> </ol>","title":"Helm Diff Plugin"},{"location":"getting-started/prerequisites/#openjdk","text":"<p>Detailed installation instructions for OpenJDK can be found here. Alternatively, you can install OpenJDK by following the instructions below.</p> <ol> <li> <p>Install with the command.</p> <pre><code>sudo apt-get install openjdk-8-jdk\n</code></pre> </li> <li> <p>Verify your installation.</p> <pre><code>java -version\n</code></pre> </li> </ol>","title":"OpenJDK"},{"location":"legal/branding-guidelines/","text":"<p>The Carbyne Stack trademark (hereinafter referred to as \"Carbyne Stack Trademarks\") is a trademark of Robert Bosch GmbH, and is treated separately from the copyright and patent license grants contained in the Carbyne Stack repositories on GitHub.</p>  <p>Important</p> <p>Any use of the Carbyne Stack Trademarks other than those explicitly permitted in these guidelines must be approved by Robert Bosch GmbH in advance (for getting in touch please see the contact information).</p>","title":"Branding Guidelines"},{"location":"legal/branding-guidelines/#acceptable-uses","text":"<p>Carbyne Stack is an open project. You may use the Carbyne Stack Trademarks to refer to the project without prior written permission in accordance with the guidelines specified in this document.</p> <p>Uses that do not require prior approval are the following:</p> <ul> <li>Give reference to the Carbyne Stack project itself</li> <li>Link to the carbynestack.io website</li> <li>Refer to original source code or other files shared by the   Carbyne Stack repositories on GitHub</li> <li>Blog posts, news articles, or educational materials about Carbyne Stack</li> </ul>","title":"Acceptable Uses"},{"location":"legal/branding-guidelines/#uses-subject-to-approval","text":"<p>Exemplary uses of the Carbyne Stack Trademarks that do require prior approval by Robert Bosch GmbH are the following (non-exhaustive list):</p> <ul> <li>Use as or integrate as part of your application icon or other design elements</li> <li>Create and use a modified or derived version</li> <li>Refer to modified versions of the Carbyne Stack platform including but not   limited to forks</li> </ul> <p>Robert Bosch GmbH reserves the right to deny trademark permission for certain use cases if the use case is not in the interest of the Carbyne Stack Community.</p>","title":"Uses Subject to Approval"},{"location":"legal/corporate-information/","text":"","title":"Corporate Information"},{"location":"legal/corporate-information/#name-and-address","text":"<p>Robert Bosch GmbH Robert-Bosch-Platz 1 70839 Gerlingen-Schillerh\u00f6he GERMANY</p>","title":"Name and Address"},{"location":"legal/corporate-information/#members-of-the-board-of-management","text":"<p>Dr. Stefan Hartung, Dr. Christian Fischer, Filiz Albrecht, Dr. Markus Forschner, Dr. Markus Heyn, Rolf Najork</p>","title":"Members of the Board of Management"},{"location":"legal/corporate-information/#your-contact-at-robert-bosch-gmbh","text":"<p>Carbyne Stack Maintainers  rng_cr_carbynestack@bosch.com  +49(711)811-0</p>","title":"Your contact at Robert Bosch GmbH"},{"location":"legal/corporate-information/#register-entries","text":"<p>Registration Court: District Court Stuttgart HRB 14000</p>","title":"Register Entries"},{"location":"legal/corporate-information/#value-added-tax-identification-number","text":"<p>DE811128135</p>","title":"Value-added tax identification number"},{"location":"legal/export-control/","text":"<p>Carbyne Stack includes cryptographic software. The country in which you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of encryption software. Before using any encryption software, please check your country's laws, regulations and policies concerning the import, possession, or use, and re-export of encryption software, to see if this is permitted. See the Wassenaar Arrangement website for more information.</p> <p>Robert Bosch GmbH has classified this software as Export Commodity Control Number (ECCN) 5D002, which includes information security software using or performing cryptographic functions with asymmetric algorithms. The form and manner of this distribution makes it eligible for export under the \"publicly available\" Section 742.15(b) and 734.3(b)(3) exemptions (see the BIS Export Administration Regulations, Section 742.15(b) and Section 734.3(b)(3)) for both object code and source code.</p> <p>The following export control compliance notifications have been delivered to  crypt@bis.doc.gov and  enc@nsa.gov as of the dates set forth below.</p>    Key Value     Project Carbyne Stack   Sent 2021-07-21   SUBMISSION TYPE EAR 742.15(b) and 734.3(b)(3)   SUBMITTED BY Sven Trieflinger   SUBMITTED FOR Robert Bosch GmbH   POINT OF CONTACT Sven Trieflinger   MANUFACTURER(S) Robert Bosch GmbH   PRODUCT NAME/MODEL Carbyne Stack Project   ECCN 5D002   INTERNET LOCATION(S) https://carbynestack.io, https://github.com/carbynestack","title":"Export Control"},{"location":"legal/privacy-policy/","text":"","title":"Privacy Policy"},{"location":"legal/privacy-policy/#github-pages-service","text":"<p>This Website is hosted as a GitHub Pages website. GitHub may collect User Personal Information from visitors to this GitHub Pages website, including logs of visitor IP addresses, to comply with legal obligations, and to maintain the security and integrity of this Website and the Service. See the GitHub Privacy Statement for details.</p>","title":"GitHub Pages Service"},{"location":"legal/privacy-policy/#data-collection","text":"","title":"Data Collection"},{"location":"legal/privacy-policy/#website-analytics","text":"<p>We want to process as little personal information as possible when you use our website. That's why we've chosen Fathom Analytics for our website analytics, which doesn't use cookies and complies with the GDPR, ePrivacy (including PECR), COPPA and CCPA. Using this privacy-friendly website analytics software, your IP address is only briefly processed, and we (running this website) have no way of identifying you. As per the CCPA, your personal information is de-identified. You can read more about this on Fathom Analytics' website.</p> <p>The purpose of us using this software is to understand our website traffic in the most privacy-friendly way possible so that we can continually improve our website and business. The lawful basis as per the GDPR is \"f); where our legitimate interests are to improve the Carbyne Stack website and open source project continually.\" As per the explanation, no personal data is stored over time.</p>","title":"Website Analytics"},{"location":"legal/privacy-policy/#cookie-usage","text":"<p>This Website does not use cookies.</p>","title":"Cookie Usage"},{"location":"legal/privacy-policy/#linked-services","text":"<p>This website contains links to other services. If you follow these links, you should become aware of their terms of service.</p> <p>We link to:</p> <ul> <li>GitHub   for documentation and source code repositories.</li> </ul> <p>Additional links might occur in the documentation.</p>","title":"Linked services"}]}